# Active Learning Chatbot

An intelligent chatbot that continuously learns and updates its knowledge through active learning. The system validates its answers against web sources, identifies outdated information, and fine-tunes itself with new facts.

## ğŸ¯ Features

- **Automatic Fact Validation**: Validates chatbot answers against Google Search results
- **LLM-as-a-Judge**: Uses the model itself to compare and validate answers
- **Asymmetric Learning**:
  - 100 samples for stable/correct facts (prevent forgetting)
  - 500 samples for outdated facts (force learning)
- **Dynamic Model Versioning**: Automatically manages model versions and paths
- **Continuous Improvement**: Each training cycle produces a smarter model

## ğŸ“ Project Structure

```
active-learning-chatbot/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ model_config.py         # All configuration settings
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ generator.py        # Training sample generation
â”‚   â”‚   â””â”€â”€ tokenizer.py        # Dataset preparation
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ loader.py           # Model loading utilities
â”‚   â”‚   â””â”€â”€ lora_config.py      # LoRA configuration
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ trainer.py          # Model training & saving
â”‚   â””â”€â”€ validator/
â”‚       â”œâ”€â”€ fact_checker.py     # Main validation pipeline
â”‚       â”œâ”€â”€ llm_judge.py        # LLM-as-a-Judge logic
â”‚       â””â”€â”€ web_search.py       # Google Search integration
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_questions.py       # Test question sets
â”œâ”€â”€ pipeline.py                 # Complete pipeline orchestrator
â”œâ”€â”€ run_validation_only.py      # Run validation phase only
â”œâ”€â”€ run_training_only.py        # Run training phase only
â”œâ”€â”€ run_testing_only.py         # Run testing phase only
â””â”€â”€ requirements.txt
```

## ğŸš€ Quick Start

### 1. Initilization

run the initilization shell script

```bash
./init.sh
```

### 2. Configure API Keys

Create a `.env` file in the project root, then edit `.env` and add your credentials:

```bash
GOOGLE_API_KEY=your-google-api-key-here
GOOGLE_CSE_ID=your-custom-search-engine-id-here
```

**IMPORTANT:** The `.env` file is in `.gitignore` and will NOT be committed to git. Never commit your API keys!

### 3. Interactive Validation (Manual Mode)

```bash
!python run_interactive_validation.py
```

What it does:
- Prompts you to enter 10 questions manually.
- Validates each answer against Google Search in real-time.
- Automatic Trigger:
  - If the model gets 9 or more correct: It passes (no training needed).
  - If the model gets 8 or fewer correct: It automatically triggers the fine-tuning pipeline to learn from your new questions.



## Run the Complete Pipeline

```bash
./start_pipeline.sh
```

This will:
1. âœ… Load the current chatbot model
2. âœ… Run validation against 20 test questions
3. âœ… Collect outdated facts for training
4. âœ… Fine-tune the base model with new facts
5. âœ… Save the improved model
6. âœ… Test the new model

## ğŸ”§ Running Individual Phases

### Phase 1: Validation Only (CELLS 4-6 from POC)

```python
!python run_validation_only.py
```

This will:
- Load the current model
- Test it against 20 questions
- Check answers against Google Search
- Save outdated facts to `data_for_finetuning.jsonl`

### Phase 2: Training Only (CELLS 7-10 from POC)

```python
!python run_training_only.py
```

This will:
- Load training data from `data_for_finetuning.jsonl`
- Load the base model
- Apply LoRA configuration
- Fine-tune the model
- Save as `qwen-finetuned-v{N}`

### Phase 3: Testing Only (CELL 11 from POC)

```python
!python run_testing_only.py
```

This will:
- Load the newly trained model
- Test it against all 20 questions
- Display the results

## âš™ï¸ Configuration

All settings are in `config/model_config.py`:

## ğŸ”„ How It Works

### 1. Validation Phase
```
User Question â†’ Model Answer â†’ Google Search â†’ LLM Judge â†’ Outdated?
                                                              â†“
                                                      Save to training file
```

### 2. Training Phase
```
Load JSONL â†’ Prepare Dataset â†’ Load Base Model â†’ Apply LoRA â†’ Train â†’ Save
```

### 3. Dynamic Model Management
```
First run:  base model â†’ v1
Second run: v1 â†’ v2
Third run:  v2 â†’ v3
...
```

The system automatically:
- Tracks the latest model version in `_latest_model_config.json`
- Loads the latest model for validation
- Trains on the base model for consistency
- Increments version numbers automatically

## ğŸ“Š Test Questions

The system includes 20 test questions:

**Stable Facts (10)**: Facts that don't change
- Capital of France, Highest mountain, Chemical symbols, etc.

**Changing Facts (10)**: Facts that update regularly
- Current president, Super Bowl winners, Oscar winners, etc.

## ğŸ“„ License

This project uses the Qwen2.5 model from Unsloth, subject to their respective licenses.

## ğŸ™ Acknowledgments

- **Unsloth** for efficient fine-tuning
- **Qwen Team** for the base model
- **Google Custom Search API** for fact validation
